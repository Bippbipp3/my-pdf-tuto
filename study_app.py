import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader

# --- 1. API í‚¤ ì„¤ì • (ë³¸ì¸ì˜ API í‚¤ë§Œ ì •í™•íˆ ë„£ì–´ì£¼ì„¸ìš”) ---
import streamlit as st
import google.generativeai as genai

# ì§ì ‘ í‚¤ë¥¼ ì ì§€ ì•Šê³  st.secretsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=API_KEY)

# --- 2. AI ëª¨ë¸ ì„¤ì • ---
model = genai.GenerativeModel(
    model_name="gemini-flash-latest",
    system_instruction="ë„ˆëŠ” PDF í•™ìŠµ ë³´ì¡° AIë‹¤. ì—…ë¡œë“œëœ ë‚´ìš©ìœ¼ë¡œë§Œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜."
)

# --- 3. ì•± í™”ë©´ êµ¬ì„± ---
st.set_page_config(page_title="PDF í•™ìŠµ ë¹„ì„œ", layout="centered")
st.title("ğŸ“š ì‹¬í”Œ PDF í•™ìŠµ ë¹„ì„œ")
st.caption("êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì—†ì´ ê¹”ë”í•˜ê²Œ ëŒ€í™”ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# ëŒ€í™” ê¸°ë¡ ë° PDF í…ìŠ¤íŠ¸ ì €ì¥ìš© ì„¸ì…˜
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "pdf_text" not in st.session_state:
    st.session_state.pdf_text = ""

# --- 4. ì‚¬ì´ë“œë°” (PDF ì—…ë¡œë“œ) ---
with st.sidebar:
    st.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”", type="pdf")
    
    if uploaded_file:
        # ìƒˆë¡œìš´ íŒŒì¼ì´ ì˜¬ë¼ì˜¤ë©´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        reader = PdfReader(uploaded_file)
        full_text = ""
        for page in reader.pages:
            full_text += page.extract_text()
        st.session_state.pdf_text = full_text
        st.success("PDF ë¡œë“œ ì™„ë£Œ!")
    
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.chat_history = []
        st.rerun()

# --- 5. ëŒ€í™”ì°½ í‘œì‹œ ---
for role, text in st.session_state.chat_history:
    with st.chat_message(role):
        st.markdown(text)

# --- 6. ì§ˆë¬¸ ì²˜ë¦¬ ---
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    if not st.session_state.pdf_text:
        st.warning("PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.chat_history.append(("user", prompt))
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ë‹µë³€ ìƒì„±
        try:
            full_prompt = f"ë¬¸ì„œ ë‚´ìš©: {st.session_state.pdf_text}\n\nì§ˆë¬¸: {prompt}"
            response = model.generate_content(full_prompt)
            
            with st.chat_message("assistant"):
                st.markdown(response.text)
            st.session_state.chat_history.append(("assistant", response.text))
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
